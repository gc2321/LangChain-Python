{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0kRYiISlD1eW2WO0h6gAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gc2321/LangChain-Python/blob/main/5_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "0rhqmgDGfXS4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet langchain-openai langchain-community\n",
        "!pip install -quiet openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWtxT39ffGb6",
        "outputId": "edf128e4-4b9a-4755-93fd-f08a852f239a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ9bQosqpV5k",
        "outputId": "5d34727d-c0e3-4276-b118-a489ecf7676f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_api =\"/content/gdrive/MyDrive/llm/api_key.txt\"\n",
        "f = open(open_ai_api)\n",
        "api_key = f.read()"
      ],
      "metadata": {
        "id": "__dZDI4qp9JP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "CQXfi3im9qIz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Basics"
      ],
      "metadata": {
        "id": "jyIn-cFDPsn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, initialize_agent, AgentType"
      ],
      "metadata": {
        "id": "JuPEwo-zZ0mW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "6qgNBNZtCSxk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "WrZ6CdsWDaSO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "kSejha8eCle9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOdgsLNcDheQ",
        "outputId": "32604707-3186-4b68-ef54-15fe1d5d9038"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(AgentType)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6C7D_AsDk3L",
        "outputId": "27778abc-265f-4d09-922f-0f375acdb477"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CHAT_CONVERSATIONAL_REACT_DESCRIPTION',\n",
              " 'CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
              " 'CONVERSATIONAL_REACT_DESCRIPTION',\n",
              " 'OPENAI_FUNCTIONS',\n",
              " 'OPENAI_MULTI_FUNCTIONS',\n",
              " 'REACT_DOCSTORE',\n",
              " 'SELF_ASK_WITH_SEARCH',\n",
              " 'STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
              " 'ZERO_SHOT_REACT_DESCRIPTION',\n",
              " '__class__',\n",
              " '__doc__',\n",
              " '__members__',\n",
              " '__module__']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "2iS-cLeSEAAs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is 1123 times 131445?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "NaX5X65XELXz",
        "outputId": "bfe1020a-ce5a-443f-808b-69d4b8301e1a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the Calculator tool to multiply these two numbers.\n",
            "Action: Calculator\n",
            "Action Input: 1123 * 131445\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 147612735\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 147612735\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'147612735'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1123 * 131445"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvz1b2V8EWYa",
        "outputId": "169b76d4-23ed-4a9d-e5ce-40438556e887"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147612735"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Tools"
      ],
      "metadata": {
        "id": "Bgyutf08E99L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uauoz-LYEbqC",
        "outputId": "e55fb6e1-acd5-4686-f6f6-d1fc64c02008"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=397bc735e19ddb4cfb1c016d05235959d082de67680ed41f5ca4301fe73b024f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_api =\"/content/gdrive/MyDrive/llm/serpapi.txt\"\n",
        "f = open(open_ai_api)\n",
        "serpapi_key = f.read()"
      ],
      "metadata": {
        "id": "1fsxayxBGxjK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['SERPAPI_API_KEY'] = serpapi_key"
      ],
      "metadata": {
        "id": "IgjPTv9WHo2w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "lmV3r93LHwwh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"serpapi\",\"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "y_qoTpmrIeqb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "3QgoJx26I1sw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What was the year Albert Einstein born? What is the result of that year multiple by 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "MoDTSo4KJPsx",
        "outputId": "0bdbc99a-1be2-488c-acf2-54ef6ce53b47"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out the year Albert Einstein was born and then multiply that by 5.\n",
            "Action: Search\n",
            "Action Input: \"Albert Einstein birth year\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m1879\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mNow I need to multiply 1879 by 5.\n",
            "Action: Calculator\n",
            "Action Input: 1879 * 5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 9395\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 9395\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9395'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1879 * 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmyStOvyJfqR",
        "outputId": "3a1a800b-147b-4a71-bc0a-a3297111334a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9395"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute Python"
      ],
      "metadata": {
        "id": "T72xLrbYJyEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-experimental==0.0.48"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYPyCT1uKcMo",
        "outputId": "858cc85a-5997-46fc-acca-148922d862a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-experimental==0.0.48\n",
            "  Downloading langchain_experimental-0.0.48-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain<0.2,>=0.1 (from langchain-experimental==0.0.48)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.7 (from langchain-experimental==0.0.48)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (0.6.6)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2,>=0.1->langchain-experimental==0.0.48)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2,>=0.1->langchain-experimental==0.0.48)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2,>=0.1->langchain-experimental==0.0.48) (8.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.7->langchain-experimental==0.0.48) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.7->langchain-experimental==0.0.48) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.7->langchain-experimental==0.0.48) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->langchain-experimental==0.0.48) (1.0.0)\n",
            "Installing collected packages: langchain-core, langchain-text-splitters, langchain-community, langchain, langchain-experimental\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.3\n",
            "    Uninstalling langchain-core-0.2.3:\n",
            "      Successfully uninstalled langchain-core-0.2.3\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.2.0\n",
            "    Uninstalling langchain-text-splitters-0.2.0:\n",
            "      Successfully uninstalled langchain-text-splitters-0.2.0\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.2.1\n",
            "    Uninstalling langchain-community-0.2.1:\n",
            "      Successfully uninstalled langchain-community-0.2.1\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.2.1\n",
            "    Uninstalling langchain-0.2.1:\n",
            "      Successfully uninstalled langchain-0.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.1.8 requires langchain-core<0.3,>=0.2.2, but you have langchain-core 0.1.52 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-experimental-0.0.48 langchain-text-splitters-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    from langchain_experimental.tools import PythonREPLTool\n",
        "    from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent"
      ],
      "metadata": {
        "id": "VTnlGJyCJkm5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "9ENeEx7WKsd3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_python_agent(tool=PythonREPLTool(), llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "3tmzcCroLAWQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_list = [1, 3, 6, 25, 7, 23, 2, 78]"
      ],
      "metadata": {
        "id": "kCWpF8UsLM17"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(f'''Sort this Python list: {python_list}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "xF2PgNR3LfNa",
        "outputId": "e2c27517-414c-43b0-c3c1-10f0156afd3e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mWe can use the `sorted()` function to sort the list in ascending order.\n",
            "Action: Python_REPL\n",
            "Action Input: sorted([1, 3, 6, 25, 7, 23, 2, 78])\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe list has been sorted in ascending order.\n",
            "Final Answer: [1, 2, 3, 6, 7, 23, 25, 78]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[1, 2, 3, 6, 7, 23, 25, 78]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Tools"
      ],
      "metadata": {
        "id": "rLdJnFSvMOGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "E8sEeK5tLnxc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import tool"
      ],
      "metadata": {
        "id": "xxWPZGz1ND30"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doc-str give context when this tool would be relevant\n",
        "# decorate with @tool to render function as a tool\n",
        "\n",
        "@tool\n",
        "def coolest_guy(text: str) -> str:\n",
        "  '''Returns the name of the coolest person in the universe.\n",
        "  Expects an input of an empty string '' and returns the name of the coolest person in the university'''\n",
        "  return \"My Guy\""
      ],
      "metadata": {
        "id": "N7ADw_WNNG3c"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "a-87zwA9OAq_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"serpapi\",\"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "cEO7bM_dOEgU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "4fJnunUQORtb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"what is the name of the coolest person in the universe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "dRJRyQNcOYLW",
        "outputId": "e4c28b24-bd95-42fa-fb2e-f2c4fd8be6f2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the coolest_guy tool to find out the name of the coolest person.\n",
            "Action: coolest_guy\n",
            "Action Input: ''\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mMy Guy\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI need to provide the name \"My Guy\" as the final answer.\n",
            "Final Answer: My Guy\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My Guy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = tools + [coolest_guy]"
      ],
      "metadata": {
        "id": "ON0Z-CG7Oke9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "Tn38JVl6Ou8b"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"what is the name of the coolest person in the universe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "VeXeFV8YO1Ql",
        "outputId": "7764ee62-d0ca-45f6-fc58-ebe169144dc2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the coolest_guy function to find out the name of the coolest person.\n",
            "Action: coolest_guy\n",
            "Action Input: ''\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mMy Guy\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have the answer to the question.\n",
            "Final Answer: My Guy\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My Guy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "SOAG7QifO3SQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(datetime.now())"
      ],
      "metadata": {
        "id": "BALGkQeePoYj",
        "outputId": "3cb263b2-c4a6-4bd5-f060-61fb3f78bcf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2024-06-02 13:58:56.623691'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_current_time(text: str) -> str:\n",
        "  '''\n",
        "  Return the current time. Use this for any questions regarding the current time. Input is an empty string\n",
        "  and the current time is returned in a string format.\n",
        "  '''\n",
        "  return str(datetime.now())"
      ],
      "metadata": {
        "id": "-iSLNimyPqjp"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = tools + [get_current_time]"
      ],
      "metadata": {
        "id": "OF9QO37wQQHn"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "fiqSMn2AQZrH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is the current time?\")"
      ],
      "metadata": {
        "id": "0Qevj-w5Qc2N",
        "outputId": "9a6dcb13-5306-4144-b151-75baa6d54ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the get_current_time tool to find out the current time.\n",
            "Action: get_current_time\n",
            "Action Input: ''\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m2024-06-02 14:02:42.384178\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have the current time now.\n",
            "Final Answer: The current time is 2024-06-02 14:02:42.384178.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current time is 2024-06-02 14:02:42.384178.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation Agents"
      ],
      "metadata": {
        "id": "BqHWLgRIRfPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "_POdoHjXQm0Z"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key='chat_history')"
      ],
      "metadata": {
        "id": "Lw_o7pApRr_n"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "sdiSyCazRyYW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "mTxxyxwWR2SO"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "                         memory=memory,\n",
        "                         verbose=True)"
      ],
      "metadata": {
        "id": "ouPtl4dXR9jN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input='What are some good Thai recipes?')"
      ],
      "metadata": {
        "id": "w0WF82LNSNWH",
        "outputId": "7ca23c69-bc65-48b7-938e-8ac870c2fc09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Thai cuisine is known for its aromatic herbs and spices, balanced flavors, and vibrant colors. Some popular Thai recipes include green curry, pad Thai, tom yum soup, mango sticky rice, and som tum (green papaya salad). Thai cuisine offers a wide range of dishes that cater to different tastes and preferences. Let me know if you would like more information on any specific Thai recipe!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thai cuisine is known for its aromatic herbs and spices, balanced flavors, and vibrant colors. Some popular Thai recipes include green curry, pad Thai, tom yum soup, mango sticky rice, and som tum (green papaya salad). Thai cuisine offers a wide range of dishes that cater to different tastes and preferences. Let me know if you would like more information on any specific Thai recipe!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input='Which one of the dishes tends to be popular in Southern Thailand?')"
      ],
      "metadata": {
        "id": "OJCAGoxSSVEC",
        "outputId": "bd896b0e-1f81-4eac-dec7-6184a8e418f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: One popular dish in Southern Thailand is Massaman curry. It is a rich and flavorful curry that combines influences from Indian, Malay, and Persian cuisines. The dish typically includes meat (such as beef or chicken), potatoes, peanuts, and a fragrant blend of spices like cinnamon, cardamom, and cloves. Massaman curry is known for its creamy texture and complex flavors, making it a favorite in Southern Thailand.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One popular dish in Southern Thailand is Massaman curry. It is a rich and flavorful curry that combines influences from Indian, Malay, and Persian cuisines. The dish typically includes meat (such as beef or chicken), potatoes, peanuts, and a fragrant blend of spices like cinnamon, cardamom, and cloves. Massaman curry is known for its creamy texture and complex flavors, making it a favorite in Southern Thailand.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input='Provide a recipe of that dish')"
      ],
      "metadata": {
        "id": "YrUUl-FCS1hK",
        "outputId": "f25ab6d2-3a26-4b76-866e-1a147dbbcd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Here is a recipe for Massaman curry, a popular dish in Southern Thailand:\n",
            "\n",
            "Ingredients:\n",
            "- 1 1/2 lbs beef (or chicken), cut into bite-sized pieces\n",
            "- 1 can (14 oz) coconut milk\n",
            "- 1/2 cup Massaman curry paste\n",
            "- 1 onion, chopped\n",
            "- 2 potatoes, peeled and cut into chunks\n",
            "- 1/2 cup roasted peanuts\n",
            "- 2 tbsp fish sauce\n",
            "- 2 tbsp palm sugar (or brown sugar)\n",
            "- 1 cinnamon stick\n",
            "- 3 cardamom pods\n",
            "- 3 cloves\n",
            "- 1 star anise\n",
            "- 1 bay leaf\n",
            "- 1 cup water\n",
            "- Fresh cilantro for garnish\n",
            "\n",
            "Instructions:\n",
            "1. In a large pot, heat some oil over medium heat and add the curry paste. Cook for a few minutes until fragrant.\n",
            "2. Add the beef (or chicken) and cook until browned on all sides.\n",
            "3. Add the coconut milk, onion, potatoes, peanuts, fish sauce, sugar, and spices. Stir well to combine.\n",
            "4. Add water and bring to a boil. Reduce heat and simmer for about 1-1.5 hours, or until the meat is tender.\n",
            "5. Taste and adjust seasoning as needed.\n",
            "6. Serve hot with steamed rice and garnish with fresh cilantro.\n",
            "\n",
            "Enjoy your homemade Massaman curry!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is a recipe for Massaman curry, a popular dish in Southern Thailand:\\n\\nIngredients:\\n- 1 1/2 lbs beef (or chicken), cut into bite-sized pieces\\n- 1 can (14 oz) coconut milk\\n- 1/2 cup Massaman curry paste\\n- 1 onion, chopped\\n- 2 potatoes, peeled and cut into chunks\\n- 1/2 cup roasted peanuts\\n- 2 tbsp fish sauce\\n- 2 tbsp palm sugar (or brown sugar)\\n- 1 cinnamon stick\\n- 3 cardamom pods\\n- 3 cloves\\n- 1 star anise\\n- 1 bay leaf\\n- 1 cup water\\n- Fresh cilantro for garnish\\n\\nInstructions:\\n1. In a large pot, heat some oil over medium heat and add the curry paste. Cook for a few minutes until fragrant.\\n2. Add the beef (or chicken) and cook until browned on all sides.\\n3. Add the coconut milk, onion, potatoes, peanuts, fish sauce, sugar, and spices. Stir well to combine.\\n4. Add water and bring to a boil. Reduce heat and simmer for about 1-1.5 hours, or until the meat is tender.\\n5. Taste and adjust seasoning as needed.\\n6. Serve hot with steamed rice and garnish with fresh cilantro.\\n\\nEnjoy your homemade Massaman curry!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MP39rBJvTA59"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}