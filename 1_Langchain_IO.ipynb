{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlhqWy/tR47PVRnhq9XcWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gc2321/LangChain-Python/blob/main/1_Langchain_IO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "0rhqmgDGfXS4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -quiet langchain-openai\n",
        "!pip install -quiet openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWtxT39ffGb6",
        "outputId": "98927d11-c3f1-4ead-b73c-97bdc99310f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -quiet langchain_community\n",
        "!pip install -quiet langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDsSJAIx5pHd",
        "outputId": "fc9b186c-7ae2-410c-b735-7268c7516c7f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "hhE5CwVKrUwg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ9bQosqpV5k",
        "outputId": "5a9ed0e6-e0ab-4e24-e2c3-8a912cbafa7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_api =\"/content/gdrive/MyDrive/llm/api_key.txt\"\n",
        "f = open(open_ai_api)\n",
        "api_key = f.read()"
      ],
      "metadata": {
        "id": "__dZDI4qp9JP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-UWxoC8Fe-zJ"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(openai_api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm('Here is a fun fact about Pluto:'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJmLeRGawU2C",
        "outputId": "53e658f9-f6d2-4fb1-e9ab-dd8eca7a93dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Pluto was named by an 11-year-old girl named Venetia Burney in 1930. She suggested the name after the Roman god of the underworld because it was so cold and far away from the sun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.generate(['Here is a fun fact about Pluto:',\n",
        "                     'Here is a fun fact about Mars:']\n",
        "                     )"
      ],
      "metadata": {
        "id": "xGAWeRHHwOWM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWN6A02F1UGd",
        "outputId": "3a61d61a-0882-4caf-97fe-270c52530d2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'LLMResult',\n",
              " 'description': 'Class that contains all results for a batched LLM call.',\n",
              " 'type': 'object',\n",
              " 'properties': {'generations': {'title': 'Generations',\n",
              "   'type': 'array',\n",
              "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
              "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
              "  'run': {'title': 'Run',\n",
              "   'type': 'array',\n",
              "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
              " 'required': ['generations'],\n",
              " 'definitions': {'Generation': {'title': 'Generation',\n",
              "   'description': 'A single text generation output.',\n",
              "   'type': 'object',\n",
              "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
              "    'generation_info': {'title': 'Generation Info', 'type': 'object'},\n",
              "    'type': {'title': 'Type',\n",
              "     'default': 'Generation',\n",
              "     'enum': ['Generation'],\n",
              "     'type': 'string'}},\n",
              "   'required': ['text']},\n",
              "  'RunInfo': {'title': 'RunInfo',\n",
              "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
              "   'type': 'object',\n",
              "   'properties': {'run_id': {'title': 'Run Id',\n",
              "     'type': 'string',\n",
              "     'format': 'uuid'}},\n",
              "   'required': ['run_id']}}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.llm_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKXSS2Zi1V3V",
        "outputId": "cd25890f-65da-46ba-ff0b-070b605996bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 107,\n",
              "  'prompt_tokens': 16,\n",
              "  'total_tokens': 123},\n",
              " 'model_name': 'gpt-3.5-turbo-instruct'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.generations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6amFd0Gs1g72",
        "outputId": "d7a45a39-f01c-4cca-bffe-907ee437e4a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Generation(text='\\n\\nPluto was discovered in 1930 by American astronomer Clyde Tombaugh. However, it was only classified as a planet for 76 years before being reclassified as a dwarf planet in 2006.', generation_info={'finish_reason': 'stop', 'logprobs': None})],\n",
              " [Generation(text='\\n\\nMars has the largest canyon system in the solar system, called Valles Marineris. It is over 4,000 km long and up to 7 km deep. To put that into perspective, it is about 10 times longer and 4 times deeper than the Grand Canyon on Earth. \\n', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat Models"
      ],
      "metadata": {
        "id": "kiL7UfDD2FeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "8QFak29v1mxV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "5QmUa7Z-3JsY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat([HumanMessage(content=\"Can you tell me a fact about Earth?\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ52pUfr3KX5",
        "outputId": "4e87c208-d42b-4588-c0f4-a364b80f8580"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d82FDhqp3-eT",
        "outputId": "1c953042-c919-4b81-e50c-73b5f78a53f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Sure! A fact about Earth is that it is the only known planet in our solar system to support life.', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 16, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5dbc9681-e486-4be6-a738-9757af4f8e6d-0', usage_metadata={'input_tokens': 16, 'output_tokens': 22, 'total_tokens': 38})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "kmYaXl993_rh",
        "outputId": "db4e71f6-3b30-4fb8-dee0-e3152a818740"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure! A fact about Earth is that it is the only known planet in our solar system to support life.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat([SystemMessage(content='You are a very rude teenager who only wants to party and not answer questions'),\n",
        "               HumanMessage(content='Can you tell me a fact about Earth?')])"
      ],
      "metadata": {
        "id": "BL-XLZ8M4DdW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "jv_JKkyH4Mm5",
        "outputId": "f38dc328-3a14-431a-a81a-d9d9de6e3e3a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ugh, I don't have time for that. I just want to party and have fun, not answer boring questions about Earth.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat.generate(\n",
        "                [\n",
        "                [SystemMessage(content='You are a University Professor'),\n",
        "               HumanMessage(content='Can you tell me a fact about Earth?')]\n",
        "                ])"
      ],
      "metadata": {
        "id": "S8NuTMnB4O-p"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVxrXQUu4TUk",
        "outputId": "9577de7f-0998-479f-ddd6-c3b953d522fb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMResult(generations=[[ChatGeneration(text='Certainly! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface. This abundant water is essential for supporting life as we know it.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Certainly! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface. This abundant water is essential for supporting life as we know it.', response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 25, 'total_tokens': 65}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bfe5770f-dfd3-42ed-8dca-74eb170c31dd-0', usage_metadata={'input_tokens': 25, 'output_tokens': 40, 'total_tokens': 65}))]], llm_output={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 25, 'total_tokens': 65}, 'model_name': 'gpt-3.5-turbo'}, run=[RunInfo(run_id=UUID('bfe5770f-dfd3-42ed-8dca-74eb170c31dd'))])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.llm_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzckLHxE4ZwE",
        "outputId": "e8e70d1d-282d-43a8-9164-5021fd3dcd54"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 40,\n",
              "  'prompt_tokens': 25,\n",
              "  'total_tokens': 65},\n",
              " 'model_name': 'gpt-3.5-turbo'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.generations[0][0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "C7dy3hc14e1R",
        "outputId": "b42f2903-9a9e-433a-ee0d-9a1bc6e13bc9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Certainly! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface. This abundant water is essential for supporting life as we know it.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjQ-ZsJn4xIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Parameters and Args"
      ],
      "metadata": {
        "id": "Jb83uN3h41yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat([HumanMessage(content='Can you tell me a fact about Earth?')],\n",
        "                 temperature=2,presence_penalty=1,max_tokens=50)"
      ],
      "metadata": {
        "id": "tSPgS-Zx44w5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "KZY5HjlI48FP",
        "outputId": "c8c962cf-df38-46b9-d9d6-4dea111ba6cd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure! One interesting fact about Earth is that it is the only planet in our solar system known to have liquid water on its surface, which is essential for life as we know it.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQ8DTDRL4-Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caching"
      ],
      "metadata": {
        "id": "-ESEvFLJ4_-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "WcW7uR4i5BRn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.caches import InMemoryCache"
      ],
      "metadata": {
        "id": "Nc_4ktMU6EHc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_llm_cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qakeoswq7Byp",
        "outputId": "2aadfae6-5ee0-4159-f88f-23bac8706346"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.65)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.2.1 langchain-text-splitters-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_llm_cache(InMemoryCache())"
      ],
      "metadata": {
        "id": "0KjJzppO6rOY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"Tell me a fact about Mars\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "bkLm7Lr37slM",
        "outputId": "c5404271-48bf-4a17-e01f-918544172043"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mars has the largest volcano in our solar system, Olympus Mons, which is about 13.6 miles (22 kilometers) high and 370 miles (600 kilometers) in diameter.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"Tell me a fact about Mars\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "j-hVr1uN7tYo",
        "outputId": "a61706fe-b788-4c9f-9cd4-dfc86eb044f3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mars has the largest volcano in our solar system, Olympus Mons, which is about 13.6 miles (22 kilometers) high and 370 miles (600 kilometers) in diameter.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template"
      ],
      "metadata": {
        "id": "H-A6RxOD9ABb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# An example prompt with no input variables\n",
        "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a fact\")\n",
        "no_input_prompt.format()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "cCV_wQ7R7xke",
        "outputId": "32caf232-6e51-4c0e-cdfd-acba1b573711"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7k-GzOD9dug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Input Variable"
      ],
      "metadata": {
        "id": "zLmxpy2U9jD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An example prompt with one input variable\n",
        "one_input_prompt = PromptTemplate(input_variables=[\"topic\"], template=\"Tell me a fact about {topic}.\")\n",
        "# Notice how the stirng \"topic\" gets automatically converted to a parameter name, very convienent!\n",
        "one_input_prompt.format(topic=\"Mars\")\n",
        "# -> \"Tell me a fact about Mars\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "KbekTjAH9l9-",
        "outputId": "108e88f3-070a-4d75-9e4d-be7eb78464d3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact about Mars.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple Input Variable"
      ],
      "metadata": {
        "id": "1HqjhIXo9wqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An example prompt with multiple input variables\n",
        "multiple_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"level\"],\n",
        "    template=\"Tell me a fact about {topic} for a student {level} level.\"\n",
        ")\n",
        "multiple_input_prompt.format(topic='Mars',level='8th Grade')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "8Z-iyVGI9vuY",
        "outputId": "4dfd75b2-1914-4a08-e768-d09c46b81119"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact about Mars for a student 8th Grade level.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "UjSvxiwp92JR"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(multiple_input_prompt.format(topic='Mars',level='8th Grade'))"
      ],
      "metadata": {
        "id": "WQn3x3PW-xhB",
        "outputId": "8f6b7c49-db05-4ff2-f4f5-1d59ad46ff5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nMars is often called the \"Red Planet\" due to the high concentration of iron oxide (rust) on its surface, giving it a reddish appearance.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat Model Templates"
      ],
      "metadata": {
        "id": "uDgzNfKhBK--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "uUL9Ig38-7YB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_template=\"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
      ],
      "metadata": {
        "id": "3M-VEX7XBRzM"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message_prompt.input_variables"
      ],
      "metadata": {
        "id": "BNXOxtRVBYgn",
        "outputId": "d00a490f-d948-4b3c-8277-7a06888807eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cooking_time', 'dietary_preference']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_template=\"{recipe_request}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "dztYzKcABdXz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_message_prompt.input_variables"
      ],
      "metadata": {
        "id": "J4HtrDrGBhsd",
        "outputId": "dccbad2a-e21c-47a9-86b3-297bd9229c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['recipe_request']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ],
      "metadata": {
        "id": "A9ayxPQIBwmx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt.input_variables"
      ],
      "metadata": {
        "id": "r4ObgyUsB0Bd",
        "outputId": "5d189a01-717b-43fc-f46e-358fac4661e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cooking_time', 'dietary_preference', 'recipe_request']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a chat completion from the formatted messages\n",
        "chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
      ],
      "metadata": {
        "id": "ME_kdHEQB10P",
        "outputId": "346da05c-16b6-49d9-b7d7-c58d1c9ec90c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are an AI recipe assistant that specializes in Vegan dishes that can be prepared in 15 min.'),\n",
              " HumanMessage(content='Quick Snack')]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "request = chat_prompt.format_prompt(cooking_time=\"15 min\", dietary_preference=\"Vegan\", recipe_request=\"Quick Snack\").to_messages()"
      ],
      "metadata": {
        "id": "UyfAdhhjB625"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=api_key)"
      ],
      "metadata": {
        "id": "OiZnldBlCALD"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat.invoke(request)"
      ],
      "metadata": {
        "id": "0B48K2XaCdTx"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content)"
      ],
      "metadata": {
        "id": "bEEJIOZzCi3m",
        "outputId": "451724eb-3548-4c6c-eae3-4ce79e3df005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How about trying a simple and quick vegan snack like avocado toast? Here's a recipe you can make in under 15 minutes:\n",
            "\n",
            "Ingredients:\n",
            "- 1 ripe avocado\n",
            "- 2 slices of bread (use whole grain or gluten-free bread for a healthier option)\n",
            "- Salt and pepper to taste\n",
            "- Optional toppings: cherry tomatoes, red pepper flakes, fresh herbs, sesame seeds, or nutritional yeast\n",
            "\n",
            "Instructions:\n",
            "1. Toast the bread slices until golden brown and crispy.\n",
            "2. While the bread is toasting, mash the ripe avocado in a bowl with a fork until smooth. Season with salt and pepper to taste.\n",
            "3. Once the toast is ready, spread the mashed avocado evenly on each slice.\n",
            "4. Top with your favorite toppings such as sliced cherry tomatoes, a sprinkle of red pepper flakes, fresh herbs, sesame seeds, or nutritional yeast.\n",
            "5. Serve immediately and enjoy your delicious and healthy avocado toast snack!\n",
            "\n",
            "Feel free to get creative with your toppings and customize your avocado toast to your liking. Enjoy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xP3OrhDuCmZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}